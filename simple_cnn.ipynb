{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow\n",
    "from keras.layers import Dense,Convolution2D,Flatten,MaxPooling2D,Reshape, Input, UpSampling2D,ZeroPadding2D,Dropout, BatchNormalization\n",
    "from keras.models import Sequential,Model\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = os.listdir(\"/home/harshitbisht96/facial_recognition_cnn/data/celebs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hrithik', 'rooney', 'monica', 'will']\n"
     ]
    }
   ],
   "source": [
    "print (dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path=\"/home/harshitbisht96/facial_recognition_cnn/data/celebs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict={'hrithik':0,'monica':1,'rooney':2,'will':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in dirs:\n",
    "    path=folder_path + ix + '/'\n",
    "    images=os.listdir(path)\n",
    "    for im in images:\n",
    "        img=image.load_img(path+im,target_size=(224,224))\n",
    "        img_array=image.img_to_array(img)\n",
    "        image_data.append(img_array)\n",
    "        labels.append(label_dict[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined=list(zip(image_data,labels))\n",
    "random.shuffle(combined)\n",
    "\n",
    "image_data[:],labels[:]=zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 224, 224, 3) (121, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train=np.array(image_data)\n",
    "X_train.shape\n",
    "\n",
    "Y_train=np.array(labels)\n",
    "Y_train=np_utils.to_categorical(Y_train)\n",
    "\n",
    "\n",
    "print (X_train.shape,Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(220, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(100, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(50, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 224, 224, 220)     6160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 112, 112, 220)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 112, 112, 100)     198100    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 112, 112, 50)      45050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 112, 112, 50)      200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 56, 56, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 56, 56, 16)        7216      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 56, 56, 8)         1160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 56, 56, 8)         32        \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 220)               5519580   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                14144     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 5,791,902\n",
      "Trainable params: 5,791,786\n",
      "Non-trainable params: 116\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "inp=Input(shape=(224,224,3))\n",
    "\n",
    "c1 = Convolution2D(220,(3,3),activation='relu',border_mode='same')(inp)\n",
    "m0 = MaxPooling2D((2,2))(c1)\n",
    "c2 = Convolution2D(100, (3,3), activation='relu',border_mode='same')(m0)\n",
    "c3 = Convolution2D(50, (3,3), activation='relu',border_mode='same')(c2)\n",
    "b0 = BatchNormalization()(c3)\n",
    "m1 = MaxPooling2D((2,2))(b0)\n",
    "c4 = Convolution2D(16, (3,3), activation='relu',border_mode='same')(m1)\n",
    "c5 = Convolution2D(8,(3,3), activation='relu', border_mode='same')(c4)\n",
    "b1 = BatchNormalization()(c5)\n",
    "f1 = Flatten()(b1)\n",
    "fc0 = Dense(220,activation='relu')(f1)\n",
    "\n",
    "fc1 = Dense(64,activation='relu')(fc0)\n",
    "\n",
    "fc2 = Dense(4,activation='softmax')(fc1)\n",
    "\n",
    "model=Model(input=inp,output=fc2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=Adam(lr=0.00003)\n",
    "model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 25 samples\n",
      "Epoch 1/5\n",
      "96/96 [==============================] - 141s 1s/step - loss: 0.6804 - acc: 0.6979 - val_loss: 0.5895 - val_acc: 0.7200\n",
      "Epoch 2/5\n",
      "96/96 [==============================] - 99s 1s/step - loss: 0.3578 - acc: 0.8464 - val_loss: 0.5499 - val_acc: 0.7300\n",
      "Epoch 3/5\n",
      "96/96 [==============================] - 113s 1s/step - loss: 0.1977 - acc: 0.9635 - val_loss: 0.5440 - val_acc: 0.7600\n",
      "Epoch 4/5\n",
      "96/96 [==============================] - 113s 1s/step - loss: 0.1020 - acc: 0.9870 - val_loss: 0.5187 - val_acc: 0.7600\n",
      "Epoch 5/5\n",
      "96/96 [==============================] - 129s 1s/step - loss: 0.0537 - acc: 0.9974 - val_loss: 0.5134 - val_acc: 0.7500\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,Y_train,\n",
    "                    shuffle = True,\n",
    "                    batch_size = 16,\n",
    "                    epochs = 5,\n",
    "                    validation_split=0.20\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrithik\n"
     ]
    }
   ],
   "source": [
    "# test_img=image.load_img(\"/home/harshitbisht96/ml-practise/test14.jpg\",target_size=(224,224))\n",
    "# test_img_array = image.img_to_array(test_img)\n",
    "# tx = np.expand_dims(test_img_array,axis=0)\n",
    "# plt.imshow(test_img)\n",
    "# ty=model.predict(tx)\n",
    "# label_dict = {v: k for k, v in label_dict.items()}\n",
    "# print (label_dict[np.argmax(ty)])\n",
    "label_dict = {v: k for k, v in label_dict.items()}\n",
    "print (label_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/harshitbisht96/ml-practise/test15.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-31279d801b7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/harshitbisht96/ml-practise/test15.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_img_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    496\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    497\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m--> 498\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2547\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2548\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2549\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/harshitbisht96/ml-practise/test15.jpg'"
     ]
    }
   ],
   "source": [
    "test_img=image.load_img(\"/home/harshitbisht96/ml-practise/test15.jpg\",target_size=(224,224))\n",
    "test_img_array = image.img_to_array(test_img)\n",
    "tx = np.expand_dims(test_img_array,axis=0)\n",
    "plt.imshow(test_img)\n",
    "ty=model.predict(tx)\n",
    "index=np.argmax(ty)\n",
    "print (label_dict[index])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print (tx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
